{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for row in df.itertuples():\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "Sparsity: 6.30%\n"
     ]
    }
   ],
   "source": [
    "print (str(n_users) + ' users')\n",
    "print (str(n_items) + ' items')\n",
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print ('Sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=10, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "\n",
    "class ExplicitMF():\n",
    "    def __init__(self, \n",
    "                 ratings, \n",
    "                 n_factors=40, \n",
    "                 item_reg=0.0, \n",
    "                 user_reg=0.0,\n",
    "                 verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        \n",
    "        item_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_reg = item_reg\n",
    "        self.user_reg = user_reg\n",
    "        self._v = verbose\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type='user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), \n",
    "                                             ratings[u, :].dot(fixed_vecs))\n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            \n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), \n",
    "                                             ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    def train(self, n_iter=10):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors\n",
    "        self.user_vecs = np.random.random((self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.random((self.n_items, self.n_factors))\n",
    "        \n",
    "        self.partial_train(n_iter)\n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            self.user_vecs = self.als_step(self.user_vecs, \n",
    "                                           self.item_vecs, \n",
    "                                           self.ratings, \n",
    "                                           self.user_reg, \n",
    "                                           type='user')\n",
    "            self.item_vecs = self.als_step(self.item_vecs, \n",
    "                                           self.user_vecs, \n",
    "                                           self.ratings, \n",
    "                                           self.item_reg, \n",
    "                                           type='item')\n",
    "            ctr += 1\n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item. \"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "                \n",
    "        return predictions\n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction. \"\"\"\n",
    "        return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "    \n",
    "    def calculate_learning_curve(self, iter_array, test):\n",
    "        \"\"\"\n",
    "        Keep track of MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        iter_array : (list)\n",
    "            List of numbers of iterations to train for each step of \n",
    "            the learning curve. e.g. [1, 5, 10, 20]\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be user x item).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iter_array\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iter_array\n",
    "        \"\"\"\n",
    "        iter_array.sort()\n",
    "        self.train_mse =[]\n",
    "        self.test_mse = []\n",
    "        iter_diff = 0\n",
    "        for (i, n_iter) in enumerate(iter_array):\n",
    "            if self._v:\n",
    "                print ( 'Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                self.train(n_iter - iter_diff)\n",
    "            else:\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse += [get_mse(predictions, test)]\n",
    "            if self._v:\n",
    "                print ( 'Train mse: ' + str(self.train_mse[-1]))\n",
    "                print ( 'Test mse: ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_ALS = ExplicitMF(train, n_factors=40, \\\n",
    "                    user_reg=0.0, item_reg=0.0)\n",
    "iter_array = [1, 2, 5, 10, 25, 50, 100]\n",
    "MF_ALS.calculate_learning_curve(iter_array, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "def plot_learning_curve(iter_array, model):\n",
    "    plt.plot(iter_array, model.train_mse, \\\n",
    "             label='Training', linewidth=5)\n",
    "    plt.plot(iter_array, model.test_mse, \\\n",
    "             label='Test', linewidth=5)\n",
    "\n",
    "\n",
    "    plt.xticks(fontsize=16);\n",
    "    plt.yticks(fontsize=16);\n",
    "    plt.xlabel('iterations', fontsize=30);\n",
    "    plt.ylabel('MSE', fontsize=30);\n",
    "    plt.legend(loc='best', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(iter_array, MF_ALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\r\n",
      "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\r\n",
      "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\r\n",
      "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\r\n",
      "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 u.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplicitMF():\n",
    "    def __init__(self, \n",
    "                 ratings,\n",
    "                 n_factors=40,\n",
    "                 learning='sgd',\n",
    "                 item_fact_reg=0.0, \n",
    "                 user_fact_reg=0.0,\n",
    "                 item_bias_reg=0.0,\n",
    "                 user_bias_reg=0.0,\n",
    "                 verbose=False):\n",
    "        \"\"\"\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        learning : (str)\n",
    "            Method of optimization. Options include \n",
    "            'sgd' or 'als'.\n",
    "        \n",
    "        item_fact_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_fact_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "            \n",
    "        item_bias_reg : (float)\n",
    "            Regularization term for item biases\n",
    "        \n",
    "        user_bias_reg : (float)\n",
    "            Regularization term for user biases\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.n_factors = n_factors\n",
    "        self.item_fact_reg = item_fact_reg\n",
    "        self.user_fact_reg = user_fact_reg\n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        self.learning = learning\n",
    "        if self.learning == 'sgd':\n",
    "            self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "            self.n_samples = len(self.sample_row)\n",
    "        self._v = verbose\n",
    "\n",
    "    def als_step(self,\n",
    "                 latent_vectors,\n",
    "                 fixed_vecs,\n",
    "                 ratings,\n",
    "                 _lambda,\n",
    "                 type='user'):\n",
    "        \"\"\"\n",
    "        One of the two ALS steps. Solve for the latent vectors\n",
    "        specified by type.\n",
    "        \"\"\"\n",
    "        if type == 'user':\n",
    "            # Precompute\n",
    "            YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(YTY.shape[0]) * _lambda\n",
    "\n",
    "            for u in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[u, :] = solve((YTY + lambdaI), \n",
    "                                             ratings[u, :].dot(fixed_vecs))\n",
    "        elif type == 'item':\n",
    "            # Precompute\n",
    "            XTX = fixed_vecs.T.dot(fixed_vecs)\n",
    "            lambdaI = np.eye(XTX.shape[0]) * _lambda\n",
    "            \n",
    "            for i in range(latent_vectors.shape[0]):\n",
    "                latent_vectors[i, :] = solve((XTX + lambdaI), \n",
    "                                             ratings[:, i].T.dot(fixed_vecs))\n",
    "        return latent_vectors\n",
    "\n",
    "    def train(self, n_iter=10, learning_rate=0.1):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors        \n",
    "        self.user_vecs = np.random.normal(scale=1./self.n_factors,\\\n",
    "                                          size=(self.n_users, self.n_factors))\n",
    "        self.item_vecs = np.random.normal(scale=1./self.n_factors,\n",
    "                                          size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        if self.learning == 'als':\n",
    "            self.partial_train(n_iter)\n",
    "        elif self.learning == 'sgd':\n",
    "            self.learning_rate = learning_rate\n",
    "            self.user_bias = np.zeros(self.n_users)\n",
    "            self.item_bias = np.zeros(self.n_items)\n",
    "            self.global_bias = np.mean(self.ratings[np.where(self.ratings != 0)])\n",
    "            self.partial_train(n_iter)\n",
    "    \n",
    "    \n",
    "    def partial_train(self, n_iter):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        ctr = 1\n",
    "        while ctr <= n_iter:\n",
    "            if ctr % 10 == 0 and self._v:\n",
    "                print ('\\tcurrent iteration: {}'.format(ctr))\n",
    "            if self.learning == 'als':\n",
    "                self.user_vecs = self.als_step(self.user_vecs, \n",
    "                                               self.item_vecs, \n",
    "                                               self.ratings, \n",
    "                                               self.user_fact_reg, \n",
    "                                               type='user')\n",
    "                self.item_vecs = self.als_step(self.item_vecs, \n",
    "                                               self.user_vecs, \n",
    "                                               self.ratings, \n",
    "                                               self.item_fact_reg, \n",
    "                                               type='item')\n",
    "            elif self.learning == 'sgd':\n",
    "                self.training_indices = np.arange(self.n_samples)\n",
    "                np.random.shuffle(self.training_indices)\n",
    "                self.sgd()\n",
    "            ctr += 1\n",
    "\n",
    "    def sgd(self):\n",
    "        for idx in self.training_indices:\n",
    "            u = self.sample_row[idx]\n",
    "            i = self.sample_col[idx]\n",
    "            prediction = self.predict(u, i)\n",
    "            e = (self.ratings[u,i] - prediction) # error\n",
    "            \n",
    "            # Update biases\n",
    "            self.user_bias[u] += self.learning_rate * \\\n",
    "                                (e - self.user_bias_reg * self.user_bias[u])\n",
    "            self.item_bias[i] += self.learning_rate * \\\n",
    "                                (e - self.item_bias_reg * self.item_bias[i])\n",
    "            \n",
    "            #Update latent factors\n",
    "            self.user_vecs[u, :] += self.learning_rate * \\\n",
    "                                    (e * self.item_vecs[i, :] - \\\n",
    "                                     self.user_fact_reg * self.user_vecs[u,:])\n",
    "            self.item_vecs[i, :] += self.learning_rate * \\\n",
    "                                    (e * self.user_vecs[u, :] - \\\n",
    "                                     self.item_fact_reg * self.item_vecs[i,:])\n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        if self.learning == 'als':\n",
    "            return self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "        elif self.learning == 'sgd':\n",
    "            prediction = self.global_bias + self.user_bias[u] + self.item_bias[i]\n",
    "            prediction += self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "            return prediction\n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item.\"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]))\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "                \n",
    "        return predictions\n",
    "    \n",
    "    def calculate_learning_curve(self, iter_array, test, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Keep track of MSE as a function of training iterations.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        iter_array : (list)\n",
    "            List of numbers of iterations to train for each step of \n",
    "            the learning curve. e.g. [1, 5, 10, 20]\n",
    "        test : (2D ndarray)\n",
    "            Testing dataset (assumed to be user x item).\n",
    "        \n",
    "        The function creates two new class attributes:\n",
    "        \n",
    "        train_mse : (list)\n",
    "            Training data MSE values for each value of iter_array\n",
    "        test_mse : (list)\n",
    "            Test data MSE values for each value of iter_array\n",
    "        \"\"\"\n",
    "        iter_array.sort()\n",
    "        self.train_mse =[]\n",
    "        self.test_mse = []\n",
    "        iter_diff = 0\n",
    "        for (i, n_iter) in enumerate(iter_array):\n",
    "            if self._v:\n",
    "                print ( 'Iteration: {}'.format(n_iter))\n",
    "            if i == 0:\n",
    "                self.train(n_iter - iter_diff, learning_rate)\n",
    "            else:\n",
    "                self.partial_train(n_iter - iter_diff)\n",
    "\n",
    "            predictions = self.predict_all()\n",
    "\n",
    "            self.train_mse += [get_mse(predictions, self.ratings)]\n",
    "            self.test_mse += [get_mse(predictions, test)]\n",
    "            if self._v:\n",
    "                print ('Train mse: ' + str(self.train_mse[-1]))\n",
    "                print ('Test mse: ' + str(self.test_mse[-1]))\n",
    "            iter_diff = n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_als_model = ExplicitMF(ratings, n_factors=10, learning='als', \\\n",
    "                            item_fact_reg=0.1, user_fact_reg=0.1)\n",
    "best_als_model.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 1682)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def cosine_similarity(model):\n",
    "    sim = model.item_vecs.dot(model.item_vecs.T)\n",
    "    print(type(sim))\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    print(norms.shape)\n",
    "    return sim / norms / norms.T\n",
    "\n",
    "als_sim = cosine_similarity(best_als_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return of the Jedi (1983)\n",
      "Star Wars (1977)\n",
      "Willy Wonka and the Chocolate Factory (1971)\n",
      "Men in Black (1997)\n",
      "Independence Day (ID4) (1996)\n"
     ]
    }
   ],
   "source": [
    "idx_to_movie = {}\n",
    "\n",
    "movie_idx =0\n",
    "with open('u.item', encoding = \"ISO-8859-1\") as f:\n",
    "    for line in f.readlines():\n",
    "        info = line.split('|')\n",
    "        idx_to_movie[int(info[0])-1] = info[1]\n",
    "        \n",
    "def display_top_k_movies(similarity):\n",
    "    movie_indices = np.argsort(similarity[movie_idx,:])[::-1]\n",
    "  \n",
    "    k_ctr = 0 \n",
    "    i = 1 \n",
    "    while k_ctr < 5:\n",
    "        movie = idx_to_movie[movie_indices[i]]\n",
    "        print(movie)\n",
    "        k_ctr += 1\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "display_top_k_movies(als_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [3. 2.]]\n",
      "[[1.  1. ]\n",
      " [1.5 1. ]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b1 = np.sqrt(np.diagonal(a))\n",
    "b = np.array([np.sqrt(np.diagonal(a))])\n",
    "\n",
    "\n",
    "print(a/b1)\n",
    "print (a/b/b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.35832838,  0.50077822, ..., -0.05195545,\n",
       "         0.1277171 , -0.04118441],\n",
       "       [ 0.35832838,  1.        ,  0.50272942, ...,  0.01630828,\n",
       "         0.79393385,  0.32817004],\n",
       "       [ 0.50077822,  0.50272942,  1.        , ..., -0.02178238,\n",
       "         0.12842611,  0.37698945],\n",
       "       ...,\n",
       "       [-0.05195545,  0.01630828, -0.02178238, ...,  1.        ,\n",
       "        -0.13213206, -0.30733179],\n",
       "       [ 0.1277171 ,  0.79393385,  0.12842611, ..., -0.13213206,\n",
       "         1.        ,  0.45037718],\n",
       "       [-0.04118441,  0.32817004,  0.37698945, ..., -0.30733179,\n",
       "         0.45037718,  1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item.json                  toJson.py\r\n",
      "matrix_factorization       untitled\r\n",
      "matrix_factorization.ipynb untitled1\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (matrix)",
   "language": "python",
   "name": "matrix"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
